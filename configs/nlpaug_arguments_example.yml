data_pipeline: 'AugDataPipeline'
augment_passages: true
augment_reviews: false

# Probability that each data point will be augmented
augmentation_likelihood: 1.0

flow:
    n: 1
    num_thread: 1

# Word Augmentations:

augment_backtranslation:
    device: 'cuda'
    batch_size: 32
    max_length: 300
    force_reload: false
    verbose: 0

augment_tfidf:
    model_path: '.'
    action: substitute
    name: TfIdf_Aug
    aug_min: 1
    aug_max: 10
    aug_p: 0.3
    top_k: 5
    stopwords: ~
    tokenizer: ~
    reverse_tokenizer: ~
    stopwords_regex: ~
    verbose: 0

augment_synonym:
    aug_src: wordnet
    model_path: ~
    name: Synonym_Aug
    aug_min: 1
    aug_max: 10
    aug_p: 0.3
    lang: eng
    stopwords: ~
    tokenizer: ~
    reverse_tokenizer: ~
    stopwords_regex: ~
    force_reload: false
    verbose: 0

augment_split:
    name: Slit_Aug
    aug_min: 1
    aug_max: 10
    aug_p: 0.3
    min_char: 4
    stopwords: ~
    tokenizer: ~
    reverse_tokenizer: ~
    stopwords_regex: ~
    verbose: 0

augment_spelling:
    dict_path: ~
    name: Spelling_Aug
    aug_min: 1
    aug_max: 10
    aug_p: 0.3
    stopwords: ~,
    tokenizer: ~
    reverse_tokenizer: ~
    include_reverse: true
    stopwords_regex: ~
    verbose: 0
# Sentence Augmentations:

#augment_context_embedding:
#    model_path: 'gpt2'
#    model_type: ''
#    name: ContextualWordEmbsForSentence_Aug
#    min_length: 100
#    max_length: 500
#    batch_size: 32
#    temperature: 1.0
#    top_k: 50
#    top_p:  0.9
#    device: 'cpu'
#    force_reload: False
#    silence: True
#    use_custom_api: True

augment_lambada: false

hypothetical_augment_lambada:
    threshold: ~ # Use this instead of None
    min_length: 100
    max_length: 300
    batch_size: 16
    temperature: 1.0
    top_k: 50
    top_p: 0.9
    repetition_penalty: 1.0
    name: Lambada_Aug
    device: 'cpu'
    force_reload: false
    verbose: 0

lambada_model_directory: "" # Needs to be filled out as a non-optional variable for Lambada. Will be enforced at runtime

augment_abstractive_summarization:
    model_path: t5-base
    tokenizer_path: t5-base
    min_length: 20
    max_length: 50
    batch_size: 32
    temperature: 1.0
    top_k: 50
    top_p:  0.9
    name: AbstSumm_Aug
    device: 'cpu'
    force_reload: false
    verbose: int = 0
    use_custom_api: true

augment_random_behavior:
    mode: neighbor
    action: swap # https://github.com/makcedward/nlpaug/blob/bb2fc63349bf949f6f6047ff447a0efb16983c0a/nlpaug/util/action.py
    name: RandomSent_Aug
    aug_min: 1
    aug_max: 10
    aug_p: 0.3
    tokenizer: None
    verbose: 0